{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Install all Dependencies\n"
      ],
      "metadata": {
        "id": "BJ_hbnpXmMFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtYgzoDQwMtP"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install sentence-transformers\n",
        "!pip install -q  faiss-cpu torchvision pillow requests\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install gradio\n",
        "!sudo apt update && sudo apt install ffmpeg -y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Libraries"
      ],
      "metadata": {
        "id": "3n4B4RHfmRoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "import requests\n",
        "import whisper\n",
        "import gradio as gr\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from io import BytesIO\n",
        "from torchvision import transforms\n",
        "from IPython.display import Image as IPythonImage, display, HTML\n"
      ],
      "metadata": {
        "id": "zcNsGRxt9neX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "3rA9_b72aOOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"styles.csv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content\")"
      ],
      "metadata": {
        "id": "jMX9ehWTajuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the on_bad_lines='skip' argument to skip problematic lines\n",
        "df = pd.read_csv(\"styles.csv\", on_bad_lines='skip')\n",
        "df = df.dropna(subset=[\"productDisplayName\", \"gender\", \"masterCategory\"])\n",
        "df = df.reset_index(drop=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zVX60AQHbMlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine Key Product Attributes for Embedding"
      ],
      "metadata": {
        "id": "8v0FHn0a_xuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"combined\"] = (\n",
        "    df[\"productDisplayName\"].astype(str) + \" \" +\n",
        "    df[\"gender\"].astype(str) + \" \" +\n",
        "    df[\"masterCategory\"].astype(str) + \" \" +\n",
        "    df[\"subCategory\"].astype(str) + \" \" +\n",
        "    df[\"articleType\"].astype(str) + \" \" +\n",
        "    df[\"baseColour\"].astype(str) + \" \" +\n",
        "    df[\"season\"].astype(str) + \" \" +\n",
        "    df[\"usage\"].astype(str)\n",
        ").str.lower()\n",
        "\n",
        "df[\"combined\"].head()"
      ],
      "metadata": {
        "id": "LZGBPgMJbxH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Semantic Embeddings and Build FAISS Index\n"
      ],
      "metadata": {
        "id": "cCRV-tsEGhfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the transformer model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Convert product descriptions into vector embeddings\n",
        "embeddings = model.encode(df[\"combined\"].tolist(), convert_to_numpy=True)\n",
        "\n",
        "# Create FAISS index\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 = Euclidean distance\n",
        "index.add(embeddings)"
      ],
      "metadata": {
        "id": "rhTLTbNTy8Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_products(query, top_k=5):\n",
        "    query_vec = model.encode([query])\n",
        "    D, I = index.search(np.array(query_vec), top_k)\n",
        "    results = df.iloc[I[0]].copy()\n",
        "    results[\"similarity_score\"] = D[0]\n",
        "    return results[[\"id\", \"productDisplayName\", \"gender\", \"masterCategory\", \"subCategory\", \"articleType\", \"baseColour\", \"season\", \"year\", \"usage\", \"similarity_score\"]]\n",
        ""
      ],
      "metadata": {
        "id": "HwiYGuf6zSN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_products(\"white shirt for men\")"
      ],
      "metadata": {
        "id": "QxSHUjKPzkdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_products(\"black sneakers for men\")"
      ],
      "metadata": {
        "id": "Jq0VkjqthYcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_products(\"summer cotton dress\")"
      ],
      "metadata": {
        "id": "Cy2FxtqHhlkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_products(\"formal shirt for office wear\")"
      ],
      "metadata": {
        "id": "fEvc4m2dhq8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_products(\"watch under 4000\")"
      ],
      "metadata": {
        "id": "hEFXoWXxiygu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "QAquWtl1kqjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"images.csv.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content\")"
      ],
      "metadata": {
        "id": "wZ-4SdqZi4SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_df = pd.read_csv(\"images.csv\")\n",
        "images_df.head()"
      ],
      "metadata": {
        "id": "ZNQ8n_6_kwt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Merge Product Metadata with Image URLs"
      ],
      "metadata": {
        "id": "mOSxQnxyM-4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge with product DataFrame\n",
        "df[\"id\"] = df[\"id\"].astype(int)\n",
        "# Assume 'filename' column in images_df contains the product ID\n",
        "# Extract the ID from the filename, assuming it's in the format 'id_...' or 'id.jpg'\n",
        "images_df[\"id\"] = images_df[\"filename\"].str.split(\"_|.jpg\").str[0].astype(int) # Split by '_' or '.jpg' to handle different filename formats\n",
        "\n",
        "df = pd.merge(df, images_df, on=\"id\", how=\"left\")\n",
        "\n",
        "# Store image link\n",
        "df[\"image_url\"] = df[\"link\"]\n",
        "df[[\"id\", \"productDisplayName\", \"image_url\"]].head()"
      ],
      "metadata": {
        "id": "YFOYiTF4k0Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load CLIP Model for Image Embeddings"
      ],
      "metadata": {
        "id": "U4HPGhpwNXka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CLIP model\n",
        "clip_model = SentenceTransformer('clip-ViT-B-32')\n",
        "\n",
        "# Define image transform\n",
        "clip_preprocess = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                         std=[0.26862954, 0.26130258, 0.27577711])\n",
        "])"
      ],
      "metadata": {
        "id": "a8gmE9mx457K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Image Embeddings for Visual Search"
      ],
      "metadata": {
        "id": "mEtZpLP-OPZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "image_vectors = []\n",
        "valid_indices = []\n",
        "\n",
        "for i, row in df.head(1000).iterrows():\n",
        "    try:\n",
        "        response = requests.get(row[\"image_url\"], timeout=3)\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "        # Encode the image using SentenceTransformer's encode\n",
        "        embedding = clip_model.encode(img, convert_to_tensor=False)\n",
        "        image_vectors.append(embedding)\n",
        "        valid_indices.append(i)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping image at index {i} due to error: {e}\")"
      ],
      "metadata": {
        "id": "kcCW-2Ha9O95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_vectors_np = np.vstack(image_vectors).astype(\"float32\")\n",
        "\n",
        "visual_index = faiss.IndexFlatL2(image_vectors_np.shape[1])\n",
        "visual_index.add(image_vectors_np)"
      ],
      "metadata": {
        "id": "vujIViXh_SJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Define Visual Search Function (Image → Product)"
      ],
      "metadata": {
        "id": "43tu4za5ahhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visual_search(user_image, top_k=5):\n",
        "    img = Image.open(user_image).convert(\"RGB\")\n",
        "\n",
        "    # Encode using SentenceTransformer\n",
        "    user_vec = clip_model.encode(img, convert_to_tensor=False).reshape(1, -1).astype(\"float32\")\n",
        "\n",
        "    D, I = visual_index.search(user_vec, top_k)\n",
        "\n",
        "    matched_rows = [valid_indices[idx] for idx in I[0]]\n",
        "    results = df.iloc[matched_rows].copy()\n",
        "    results[\"similarity_score\"] = D[0]\n",
        "\n",
        "    return results[[\"productDisplayName\", \"gender\", \"masterCategory\", \"subCategory\", \"articleType\", \"image_url\", \"similarity_score\"]]\n"
      ],
      "metadata": {
        "id": "CqrRTeSRAUpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## upload image"
      ],
      "metadata": {
        "id": "hsTylVribNgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fname in uploaded:\n",
        "    results = visual_search(fname)\n",
        "    display(results)"
      ],
      "metadata": {
        "id": "oLSHVTysAXLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Display Visual Search Results as Product Cards"
      ],
      "metadata": {
        "id": "aQ1hpDWCayKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_visual_results(results):\n",
        "    html = \"\"\n",
        "    for _, row in results.iterrows():\n",
        "        html += f\"\"\"\n",
        "        <div style=\"display:flex; align-items:center; margin-bottom:10px;\">\n",
        "            <img src=\"{row['image_url']}\" width=\"100\" style=\"margin-right:10px;\">\n",
        "            <div>\n",
        "                <b>{row['productDisplayName']}</b><br>\n",
        "                {row['masterCategory']} / {row['subCategory']}<br>\n",
        "                <i>{row['gender']}</i><br>\n",
        "                <b>Similarity:</b> {row['similarity_score']:.2f}\n",
        "            </div>\n",
        "        </div>\n",
        "        \"\"\"\n",
        "    display(HTML(html))\n"
      ],
      "metadata": {
        "id": "cvYAb_xuAZjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fname in uploaded:\n",
        "    results = visual_search(fname)\n",
        "    show_visual_results(results)\n"
      ],
      "metadata": {
        "id": "8LyJtlGSHOlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload Audio"
      ],
      "metadata": {
        "id": "eF06HE_qbXX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded_audio = files.upload()"
      ],
      "metadata": {
        "id": "wbBVvZ_6Kv0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transcribe Voice Input Using Whisper model by OpenAI"
      ],
      "metadata": {
        "id": "YzebRT0nb3-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "# Get the uploaded filename\n",
        "audio_file = list(uploaded_audio.keys())[0]\n",
        "\n",
        "# Transcribe to text\n",
        "transcription = whisper_model.transcribe(audio_file,language=\"en\")\n",
        "query_text = transcription[\"text\"]\n",
        "\n",
        "print(\" Voice input:\", query_text)\n",
        "\n",
        "# Reload or re-assign your SentenceTransformer model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "zras4fAqLqKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = search_products(query_text)\n",
        "display(results)"
      ],
      "metadata": {
        "id": "_0bEK535LhS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extract Filters from Natural Language Queries\n"
      ],
      "metadata": {
        "id": "MyZn20wBcqvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_filters(query):\n",
        "    filters = {\"gender\": None, \"category\": None, \"usage\": None, \"max_price\": None}\n",
        "    query = query.lower()\n",
        "\n",
        "    # Gender detection\n",
        "    if \"women\" in query or \"ladies\" in query:\n",
        "        filters[\"gender\"] = \"Women\"\n",
        "    elif \"men\" in query or \"gents\" in query:\n",
        "        filters[\"gender\"] = \"Men\"\n",
        "\n",
        "    # Usage detection\n",
        "    if \"casual\" in query:\n",
        "        filters[\"usage\"] = \"Casual\"\n",
        "    elif \"formal\" in query:\n",
        "        filters[\"usage\"] = \"Formal\"\n",
        "    elif \"sports\" in query:\n",
        "        filters[\"usage\"] = \"Sports\"\n",
        "\n",
        "    # Price detection\n",
        "    price_match = re.search(r\"under (\\d+)\", query)\n",
        "    if price_match:\n",
        "        filters[\"max_price\"] = int(price_match.group(1))\n",
        "\n",
        "    return filters"
      ],
      "metadata": {
        "id": "TU4kd8qiMoke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Perform Semantic Search with Smart Filters"
      ],
      "metadata": {
        "id": "otbZ1cerdb_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_products_with_filters(query, gender=None, category=None, usage=None, max_price=None, top_k=10):\n",
        "    # Step 1: Semantic search\n",
        "    query_vec = model.encode([query])\n",
        "    D, I = index.search(np.array(query_vec), top_k)\n",
        "    results = df.iloc[I[0]].copy()\n",
        "    results[\"similarity_score\"] = D[0]\n",
        "\n",
        "    # Step 2: Apply smart filters\n",
        "    if gender:\n",
        "        results = results[results[\"gender\"].str.lower() == gender.lower()]\n",
        "    if category:\n",
        "        results = results[results[\"masterCategory\"].str.lower() == category.lower()]\n",
        "    if usage:\n",
        "        results = results[results[\"usage\"].str.lower() == usage.lower()]\n",
        "    if max_price:\n",
        "        results = results[results[\"price\"] <= max_price]\n",
        "\n",
        "    return results.sort_values(by=\"similarity_score\")[[\n",
        "        \"productDisplayName\", \"gender\", \"masterCategory\", \"subCategory\", \"usage\", \"price\", \"similarity_score\",\"image_url\"\n",
        "    ]]\n"
      ],
      "metadata": {
        "id": "sLEDxmYxTV49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Combine Everything into a Smart Search Function"
      ],
      "metadata": {
        "id": "8oBLmMsieGld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def smart_search(query, top_k=10):\n",
        "    filters = extract_filters(query)\n",
        "\n",
        "    print(\" Auto-detected filters:\")\n",
        "    print(f\"  Gender: {filters['gender']}\")\n",
        "    print(f\"  Usage: {filters['usage']}\")\n",
        "    print(f\"  Max Price: {filters['max_price']}\")\n",
        "\n",
        "    return search_products_with_filters(\n",
        "        query=query,\n",
        "        gender=filters[\"gender\"],\n",
        "        category=filters[\"category\"],  # You can expand this later\n",
        "        usage=filters[\"usage\"],\n",
        "        max_price=filters[\"max_price\"],\n",
        "        top_k=top_k\n",
        "    )\n"
      ],
      "metadata": {
        "id": "Kdw3Mf8sS1cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simulate Product Prices for Filter-Based Search"
      ],
      "metadata": {
        "id": "cwFyGDW0earx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add random price between ₹500 and ₹4999\n",
        "np.random.seed(42)  # Ensures reproducible results\n",
        "df[\"price\"] = np.random.randint(500, 5000, size=len(df))\n",
        "\n",
        "# Check a few rows\n",
        "df[[\"productDisplayName\", \"price\"]].head()\n"
      ],
      "metadata": {
        "id": "bPGdLdb-T0Qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_search(\"white kurta for women under 1500\")"
      ],
      "metadata": {
        "id": "_z1VmoPmS4i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_search(\"denim jeans for men under 1500\")"
      ],
      "metadata": {
        "id": "LysBqGH3TEPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smart_search(\"formal shoes for men under 2000\")"
      ],
      "metadata": {
        "id": "w2uM5Nh5UBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Product Curation"
      ],
      "metadata": {
        "id": "bUZyX3Z7fZKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ai_curation(query, top_k=30):\n",
        "    # Step 1: Run smart search (with auto filters)\n",
        "    base_results = smart_search(query, top_k=top_k)\n",
        "\n",
        "    # Step 2: Curation logic\n",
        "    top_picks = base_results.head(5)\n",
        "    budget_friendly = base_results[base_results[\"price\"] < 1000].head(5)\n",
        "\n",
        "    # Optional: Use a color keyword from the query (e.g., \"white\")\n",
        "    import re\n",
        "    color_match = re.search(r\"\\b(white|black|blue|red|green|yellow|pink)\\b\", query.lower())\n",
        "    color = color_match.group(1) if color_match else None\n",
        "\n",
        "    if color:\n",
        "        similar_styles = base_results[base_results[\"productDisplayName\"].str.contains(color, case=False)].head(5)\n",
        "    else:\n",
        "        similar_styles = base_results.head(5)\n",
        "\n",
        "    # Optional personalization (dummy: show casual for women)\n",
        "    personalized = base_results[\n",
        "        (base_results[\"gender\"] == \"Women\") & (base_results[\"usage\"] == \"Casual\")\n",
        "    ].head(5)\n",
        "\n",
        "    return {\n",
        "        \" Top Picks\": top_picks,\n",
        "        \" Budget Friendly\": budget_friendly,\n",
        "        f\" Similar Styles ({color or 'default'})\": similar_styles,\n",
        "        \" For You (Personalized)\": personalized\n",
        "    }\n"
      ],
      "metadata": {
        "id": "r8jWg3LQUNQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_curated_carousels(carousels):\n",
        "    for title, df_section in carousels.items():\n",
        "        html = f\"<h3>{title}</h3><div style='display:flex; overflow-x:auto;'>\"\n",
        "        for _, row in df_section.iterrows():\n",
        "            html += f\"\"\"\n",
        "            <div style=\"margin-right:10px; text-align:center;\">\n",
        "                <img src=\"{row['image_url']}\" width=\"120\" style=\"border-radius:8px;\"><br>\n",
        "                <b>{row['productDisplayName'][:25]}</b><br>\n",
        "                ₹{row['price']} | {row['usage']}<br>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        html += \"</div><hr>\"\n",
        "        display(HTML(html))\n"
      ],
      "metadata": {
        "id": "xx5cM_YLVneo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carousels = ai_curation(\"Running shoes for women under 4500\")\n",
        "show_curated_carousels(carousels)\n"
      ],
      "metadata": {
        "id": "2L2TJG8AVps_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradio Frontend"
      ],
      "metadata": {
        "id": "SEmgXdKBIbbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Load Whisper model for audio transcription\n",
        "whisper_model = whisper.load_model(\"base\")\n",
        "\n",
        "\n",
        "def gradio_search(text_query, image=None, audio=None):\n",
        "    # Step 1: Transcribe audio if no text query is given\n",
        "    if not text_query.strip() and audio is not None:\n",
        "        transcription = whisper_model.transcribe(audio)\n",
        "        text_query = transcription[\"text\"]\n",
        "        print(\" Transcribed:\", text_query)\n",
        "\n",
        "    # Step 2: Choose search type\n",
        "    if image is not None and not text_query.strip():\n",
        "        results = visual_search(image)\n",
        "    else:\n",
        "        results = smart_search(text_query)\n",
        "\n",
        "    # Step 3: Prepare Gradio output\n",
        "    results = results.head(6)\n",
        "    items = [\n",
        "        f\"{row['productDisplayName']}\\n₹{row['price']} | {row['gender']} | {row['usage']}\\nScore: {row['similarity_score']:.2f}\"\n",
        "        for _, row in results.iterrows()\n",
        "    ]\n",
        "    return list(results[\"image_url\"]), items\n",
        "\n",
        "# --- Gradio UI Layout ---\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ONDC Smart Discovery Engine\n",
        "    Search using voice, text, or image. AI will match the most relevant products across sellers.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        text_input = gr.Textbox(label=\"Search Query\", placeholder=\"e.g. white kurta for women under 1500\")\n",
        "        image_input = gr.Image(type=\"pil\", label=\"Upload Product Image (Optional)\")\n",
        "        audio_input = gr.Audio(type=\"filepath\", label=\"Upload Voice Query (Optional)\")\n",
        "\n",
        "    search_btn = gr.Button(\"Search\")\n",
        "\n",
        "    with gr.Row():\n",
        "        result_images = gr.Gallery(label=\"Matching Products\")\n",
        "        result_texts = gr.Textbox(label=\"Product Info\", lines=10)\n",
        "\n",
        "    search_btn.click(fn=gradio_search, inputs=[text_input, image_input, audio_input], outputs=[result_images, result_texts])\n",
        "\n",
        "# Launch the app\n",
        "demo.launch(debug=False, share=True)"
      ],
      "metadata": {
        "id": "Zp8S6sAbIWZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}